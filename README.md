# 🎓 Reinforcement Learning 101

[![Twitter/X](https://img.shields.io/badge/X-@Aeriumcius-blue?style=flat&logo=twitter)](https://x.com/Aeriumcius)
[![GitHub](https://img.shields.io/badge/GitHub-armlynobinguar-black?style=flat&logo=github)](https://github.com/armlynobinguar)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Armielyn%20Obinguar-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/armielyn-obinguar/)

---

Welcome to **Reinforcement Learning 101** — a curated journey through the fundamentals and advanced topics of Reinforcement Learning, structured as a hands-on learning repo.

Whether you're new to RL or brushing up for deep dive research, this repo covers everything from Q-learning to Actor-Critic methods, Multi-Agent setups, and Bandits — with a focus on intuitive learning and practical implementations.

---

## 📁 Repository Structure

Each numbered folder represents a module in the learning path:

| Folder | Topic |
|--------|-------|
| `00_RL_Fundamentals` | Reinforcement Learning Basics and Terminology |
| `01_Introduction_to_RL` | Core Concepts and Problem Setting |
| `02_Q_Learning_Basics` | Q-Learning and Value Iteration |
| `03_Policy_Gradient_Methods` | REINFORCE, Advantage Actor-Critic |
| `04_Deep_Q_Networks` | DQNs and Experience Replay |
| `05_Actor_Critic_Methods` | Actor-Critic Variants |
| `06_Multi_Agent_RL` | Cooperative and Competitive Multi-Agent Systems |
| `07_Exploration_Strategies` | Epsilon-Greedy, Softmax, UCB, etc. |
| `08_Bandits` | Multi-Armed Bandit Problems |
| `09_Model_Based_RL` | World Models and Planning |
| `10_Function_Approximation` | Using Neural Nets for Value/Policy Approximation |
| `utils/` | Helper functions and wrappers |
| `rl_env/` | Custom or wrapped environments |

---

## 📚 Prerequisites

- Python 3.8+
- Basic understanding of machine learning
- Familiarity with OpenAI Gym and NumPy

---

## 📄 License

This project is open-sourced under the [Apache License 2.0](LICENSE).

---

Let's build smart agents, together. 🧠🤖

